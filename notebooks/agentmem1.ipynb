{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, Tool, ZeroShotAgent, create_react_agent\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_community.chat_message_histories import RedisChatMessageHistory\n",
    "from langchain_community.utilities import GoogleSearchAPIWrapper\n",
    "from langchain_openai import OpenAI\n",
    "from langchain import hub\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wandb\n",
      "  Downloading wandb-0.16.2-py3-none-any.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from wandb) (3.1.40)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from wandb) (5.9.6)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
      "  Downloading sentry_sdk-1.39.2-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Requirement already satisfied: PyYAML in /usr/local/python/3.10.13/lib/python3.10/site-packages (from wandb) (6.0.1)\n",
      "Collecting setproctitle (from wandb)\n",
      "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/python/3.10.13/lib/python3.10/site-packages (from wandb) (68.2.2)\n",
      "Collecting appdirs>=1.4.3 (from wandb)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from wandb) (4.25.2)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2023.11.17)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
      "Downloading wandb-0.16.2-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sentry_sdk-1.39.2-py2.py3-none-any.whl (254 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.1/254.1 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Installing collected packages: appdirs, setproctitle, sentry-sdk, docker-pycreds, wandb\n",
      "Successfully installed appdirs-1.4.4 docker-pycreds-0.4.0 sentry-sdk-1.39.2 setproctitle-1.3.3 wandb-0.16.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neo4j'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(\".env\")\n",
    "display(os.environ.get(\"NEO4J_USERNAME\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_WANDB_TRACING\"] = \"true\"\n",
    "os.environ[\"WANDB_NAME\"] = \"agentmem\"\n",
    "os.environ[\"WANDB_NOTES\"] = \"memoryagent\"\n",
    "os.environ[\"WANDB_PROJECT\"] = \"langchain-tracing\"\n",
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "from langchain.callbacks import wandb_tracing_enabled\n",
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "search = GoogleSearchAPIWrapper()\n",
    "# tools = [\n",
    "#     Tool(\n",
    "#         name=\"Search\",\n",
    "#         func=search.run,\n",
    "#         description=\"useful for when you need to answer questions about current events\",\n",
    "#     )\n",
    "# ]\n",
    "tools = [TavilySearchResults(max_results=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Assistant is a large language model trained by OpenAI.\n",
       "\n",
       "Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
       "\n",
       "Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
       "\n",
       "Overall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\n",
       "\n",
       "TOOLS:\n",
       "------\n",
       "\n",
       "Assistant has access to the following tools:\n",
       "\n",
       "{tools}\n",
       "\n",
       "To use a tool, please use the following format:\n",
       "\n",
       "```\n",
       "Thought: Do I need to use a tool? Yes\n",
       "Action: the action to take, should be one of [{tool_names}]\n",
       "Action Input: the input to the action\n",
       "Observation: the result of the action\n",
       "```\n",
       "\n",
       "When you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\n",
       "\n",
       "```\n",
       "Thought: Do I need to use a tool? No\n",
       "Final Answer: [your response here]\n",
       "```\n",
       "\n",
       "Begin!\n",
       "\n",
       "Previous conversation history:\n",
       "{chat_history}\n",
       "\n",
       "New input: {input}\n",
       "{agent_scratchpad}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['agent_scratchpad', 'chat_history', 'input', 'tool_names', 'tools']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "from langchain.agents.load_tools import get_all_tool_names\n",
    "from langchain import hub\n",
    "prompt = hub.pull(\"hwchase17/react-chat\")\n",
    "\n",
    "display(Markdown(prompt.template))\n",
    "display(prompt.input_variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Have a conversation with a human, answering the following questions as best you can. You have access to the following tools:\n",
       "\n",
       "{tools}\n",
       "\n",
       "Use the following format:\n",
       "\n",
       "Question: the input question you must answer\n",
       "Thought: you should always think about what to do\n",
       "Action: the action to take, should be one of [{tool_names}]\n",
       "Action Input: the input to the action\n",
       "Observation: the result of the action\n",
       "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
       "Thought: I now know the final answer\n",
       "Final Answer: the final answer to the original input question\n",
       "\n",
       "Begin!\"\n",
       "\n",
       "{chat_history}\n",
       "Question: {input}\n",
       "{agent_scratchpad}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['agent_scratchpad', 'chat_history', 'input', 'tool_names', 'tools']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    PromptTemplate,\n",
    ")\n",
    "prefix = \"\"\"Have a conversation with a human, answering the following questions as best you can. You have access to the following tools:\"\"\"\n",
    "suffix = \"\"\"Begin!\"\n",
    "\n",
    "{chat_history}\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "# prompt = ZeroShotAgent.create_prompt(\n",
    "#     tools,\n",
    "#     prefix=prefix,\n",
    "#     suffix=suffix,\n",
    "#     input_variables=[\"input\", \"chat_history\", \"agent_scratchpad\"],\n",
    "# )\n",
    "# display(Markdown(prompt.template))\n",
    "# display(prompt.input_variables)\n",
    "\n",
    "prompttemplate = \"\"\"Have a conversation with a human, answering the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\"\n",
    "\n",
    "{chat_history}\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate.from_template(prompttemplate)\n",
    "display(Markdown(PROMPT.template))\n",
    "display(PROMPT.input_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_history = RedisChatMessageHistory(\n",
    "    url=\"redis://localhost:6379/0\", ttl=600, session_id=\"my-session\"\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\", chat_memory=message_history\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4-1106-preview\",temperature=0.4)\n",
    "agent = create_react_agent(llm=llm, tools=tools, prompt=prompt)\n",
    "agent_chain = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent, tools=tools, verbose=True, memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: tavily_search_results_json\n",
      "Action Input: How many people live in Canada?\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.canadapopulation.net/', 'content': \"Population of Canada 2024 Canada Population 2024  more about Quebec population 2024.  Toronto Population 2024.  more about Nova Scotia population 2024.We believe using the recent years' figures (see the table below) will make the estimation more accurate. Population Growth of Canada The following table shows Canada is enjoying healthy and consistent population growth over last 12 years range from 0.92% to 1.00% adding 329,278 to 346,537 people to the overall population each year.\"}]\u001b[0m\u001b[32;1m\u001b[1;3mDo I need to use a tool? No\n",
      "Final Answer: The search results did not provide the current population of Canada but indicated that Canada has been experiencing a healthy and consistent population growth ranging from 0.92% to 1.00%, adding between 329,278 to 346,537 people to the overall population each year. For the most current population figure, it would be best to refer to the latest statistics from a reliable source such as Statistics Canada or a similar demographic authority.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'How many people live in canada?',\n",
       " 'chat_history': '',\n",
       " 'output': 'The search results did not provide the current population of Canada but indicated that Canada has been experiencing a healthy and consistent population growth ranging from 0.92% to 1.00%, adding between 329,278 to 346,537 people to the overall population each year. For the most current population figure, it would be best to refer to the latest statistics from a reliable source such as Statistics Canada or a similar demographic authority.'}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.invoke({\"input\":\"How many people live in canada?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we unset the environment variable and use a context manager.\n",
    "if \"LANGCHAIN_WANDB_TRACING\" in os.environ:\n",
    "    del os.environ[\"LANGCHAIN_WANDB_TRACING\"]\n",
    "\n",
    "# enable tracing using a context manager\n",
    "# with wandb_tracing_enabled():\n",
    "#     agent.run(\"What is 5 raised to .123243 power?\")  # this should be traced\n",
    "\n",
    "# agent.run(\"What is 2 raised to .123243 power?\")  # this should not be traced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```\n",
      "Thought: Do I need to use a tool? No\n",
      "Final Answer: The national anthem of Canada is called \"O Canada.\"\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "with wandb_tracing_enabled():\n",
    "    agent_chain.invoke({\"input\":\"what is their national anthem called?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
